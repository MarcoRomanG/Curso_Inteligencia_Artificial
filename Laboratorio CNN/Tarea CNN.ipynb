{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c3c87ed-53a6-4dee-a111-e029635bc86c",
   "metadata": {},
   "source": [
    "## 1. Preparación de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a888b5-1847-4b27-a3f1-cc7dfb90ef7c",
   "metadata": {},
   "source": [
    "#### Se utiliza como conjunto de datos CIFAR-10, un conjunto de datos comúnmente utilizado para la clasificación de imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4187a6a6-9f5e-45b1-9808-8f047d3a1e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Transformaciones de los datos\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Descargar y cargar los datos de entrenamiento y prueba\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=100, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce356bf-b896-4ef7-872f-b92b9bcbcafa",
   "metadata": {},
   "source": [
    "## 2. Definición de modelo, optimizador y criterio de pérdida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98bf548a-9207-4e58-8666-483c275ecec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Definición del modelo CNN\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        # Capa convolucional 1: 32 filtros, kernel 3x3, activación ReLU\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
    "        # Capa de max pooling 1: tamaño del pool 2x2\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Capa convolucional 2: 64 filtros, kernel 3x3, activación ReLU\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        # Capa de max pooling 2: tamaño del pool 2x2\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Capa convolucional 3: 64 filtros, kernel 3x3, activación ReLU\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1)\n",
    "        # Capa de max pooling 3: tamaño del pool 2x2\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Capa completamente conectada: 64 unidades, activación ReLU\n",
    "        self.fc1 = nn.Linear(64 * 4 * 4, 64)\n",
    "        # Capa de salida: 10 unidades (para clasificación en 10 clases), activación softmax\n",
    "        self.fc2 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Aplicar la primera capa convolucional seguida de ReLU y pooling\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        # Aplicar la segunda capa convolucional seguida de ReLU y pooling\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        # Aplicar la tercera capa convolucional seguida de ReLU y pooling\n",
    "        x = self.pool3(F.relu(self.conv3(x)))\n",
    "        # Aplanar las características para la capa completamente conectada\n",
    "        x = x.view(-1, 64 * 4 * 4)\n",
    "        # Aplicar la primera capa completamente conectada seguida de ReLU\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # Aplicar la capa de salida\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Crear una instancia de la red\n",
    "net = CNN()\n",
    "\n",
    "# Definir el criterio de pérdida y el optimizador\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468e8e60-10b7-4f80-9d4a-b49bb651a0cc",
   "metadata": {},
   "source": [
    "## 3. Entrenamiento de modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b9508b-c697-4816-8967-0301b306b11a",
   "metadata": {},
   "source": [
    "#### Se itera sobre los datos de entrenamiento, se calculan las predicciones del modelo, la pérdida, y se ajustan los pesos del modelo mediante retropropagación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06d9628a-ac2b-4381-b5e5-b296b1f64e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [100/500], Loss: 2.3041\n",
      "Epoch [1/10], Step [200/500], Loss: 2.3017\n",
      "Epoch [1/10], Step [300/500], Loss: 2.2993\n",
      "Epoch [1/10], Step [400/500], Loss: 2.2965\n",
      "Epoch [1/10], Step [500/500], Loss: 2.2923\n",
      "Epoch [2/10], Step [100/500], Loss: 2.2861\n",
      "Epoch [2/10], Step [200/500], Loss: 2.2719\n",
      "Epoch [2/10], Step [300/500], Loss: 2.2435\n",
      "Epoch [2/10], Step [400/500], Loss: 2.1861\n",
      "Epoch [2/10], Step [500/500], Loss: 2.1151\n",
      "Epoch [3/10], Step [100/500], Loss: 2.0564\n",
      "Epoch [3/10], Step [200/500], Loss: 1.9870\n",
      "Epoch [3/10], Step [300/500], Loss: 1.9590\n",
      "Epoch [3/10], Step [400/500], Loss: 1.9190\n",
      "Epoch [3/10], Step [500/500], Loss: 1.8916\n",
      "Epoch [4/10], Step [100/500], Loss: 1.8465\n",
      "Epoch [4/10], Step [200/500], Loss: 1.8417\n",
      "Epoch [4/10], Step [300/500], Loss: 1.7808\n",
      "Epoch [4/10], Step [400/500], Loss: 1.7554\n",
      "Epoch [4/10], Step [500/500], Loss: 1.7299\n",
      "Epoch [5/10], Step [100/500], Loss: 1.6909\n",
      "Epoch [5/10], Step [200/500], Loss: 1.6610\n",
      "Epoch [5/10], Step [300/500], Loss: 1.6375\n",
      "Epoch [5/10], Step [400/500], Loss: 1.6082\n",
      "Epoch [5/10], Step [500/500], Loss: 1.6033\n",
      "Epoch [6/10], Step [100/500], Loss: 1.5798\n",
      "Epoch [6/10], Step [200/500], Loss: 1.5727\n",
      "Epoch [6/10], Step [300/500], Loss: 1.5239\n",
      "Epoch [6/10], Step [400/500], Loss: 1.5230\n",
      "Epoch [6/10], Step [500/500], Loss: 1.5137\n",
      "Epoch [7/10], Step [100/500], Loss: 1.4898\n",
      "Epoch [7/10], Step [200/500], Loss: 1.4792\n",
      "Epoch [7/10], Step [300/500], Loss: 1.4835\n",
      "Epoch [7/10], Step [400/500], Loss: 1.4580\n",
      "Epoch [7/10], Step [500/500], Loss: 1.4435\n",
      "Epoch [8/10], Step [100/500], Loss: 1.4514\n",
      "Epoch [8/10], Step [200/500], Loss: 1.4221\n",
      "Epoch [8/10], Step [300/500], Loss: 1.4168\n",
      "Epoch [8/10], Step [400/500], Loss: 1.4077\n",
      "Epoch [8/10], Step [500/500], Loss: 1.3772\n",
      "Epoch [9/10], Step [100/500], Loss: 1.3793\n",
      "Epoch [9/10], Step [200/500], Loss: 1.3694\n",
      "Epoch [9/10], Step [300/500], Loss: 1.3348\n",
      "Epoch [9/10], Step [400/500], Loss: 1.3821\n",
      "Epoch [9/10], Step [500/500], Loss: 1.3515\n",
      "Epoch [10/10], Step [100/500], Loss: 1.3272\n",
      "Epoch [10/10], Step [200/500], Loss: 1.3343\n",
      "Epoch [10/10], Step [300/500], Loss: 1.3343\n",
      "Epoch [10/10], Step [400/500], Loss: 1.3277\n",
      "Epoch [10/10], Step [500/500], Loss: 1.2795\n",
      "Entrenamiento terminado\n"
     ]
    }
   ],
   "source": [
    "# Número de épocas de entrenamiento\n",
    "num_epochs = 10\n",
    "\n",
    "# Bucle de entrenamiento\n",
    "for epoch in range(num_epochs):  # recorrer el conjunto de datos varias veces\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # Obtener las entradas y etiquetas\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Poner a cero los gradientes de los parámetros\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Hacer forward + backward + optimizar\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Imprimir estadísticas\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:    # imprimir cada 100 mini-batches\n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(trainloader)}], Loss: {running_loss / 100:.4f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Entrenamiento terminado')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4af41ed-b068-45c9-bc60-744a73b29b71",
   "metadata": {},
   "source": [
    "## 4. Evaluación de modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331a6713-cf63-40b8-b103-aa39cf0d208e",
   "metadata": {},
   "source": [
    "#### Se evalúa el modelo utilizando el conjunto de datos de prueba, calculando la precisión global."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64d615aa-bb65-4827-91e1-e40e400de02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión de la red en las 10000 imágenes de prueba: 53.33 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# No necesitamos calcular los gradientes para la evaluación\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Precisión de la red en las 10000 imágenes de prueba: {100 * correct / total} %')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab87d378-15ad-412a-9f9b-a03c6b9a7555",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
