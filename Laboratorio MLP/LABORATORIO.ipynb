{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76bc2073-c8ac-4146-ad0f-6eb541656bf4",
   "metadata": {},
   "source": [
    "### Desafíos \n",
    "\n",
    "Para profundizar su comprensión sobre cómo los diferentes parámetros y configuraciones afectan el rendimiento del modelo, complete los siguientes desafíos:\n",
    "\n",
    "#### Desafío 1: Cambiar la Tasa de Aprendizaje del Optimizador Adam\n",
    "\n",
    "El optimizador Adam tiene una tasa de aprendizaje por defecto de 0.001. Intente cambiar esta tasa de aprendizaje a diferentes valores y observe cómo afecta el rendimiento del modelo.\n",
    "\n",
    "1. Cambie la tasa de aprendizaje a 0.01:\n",
    " \n",
    "\n",
    "2. Cambie la tasa de aprendizaje a 0.0001:\n",
    "\n",
    "**Pregunta:**\n",
    "- ¿Cómo afecta cada cambio en la tasa de aprendizaje a la precisión y la pérdida del modelo durante el entrenamiento y la validación?\n",
    "\n",
    "  Al modificar la tasa de aprendizaje por defecto, es decir de 0.001 a 0.01, la precisión obtenida durante el entrenamiento y validación fue menor,\n",
    "  mientras que la pérdida fue mayor.\n",
    "\n",
    "  Luego al modificarla a 0.0001, la precisión y la pérdida fueron similares a las obtenidas por la tasa de\n",
    "  aprendizaje por defecto.\n",
    "\n",
    "  Por lo tanto, se puede decir que a medida que la tasa de aprendizaje es menor en el optimizador Adam, la precisión obtenida\n",
    "  al utilizar el modelo es muy alta, cercana o igual al 100%.\n",
    "\n",
    "#### Desafío 2: Modificar el Número de Neuronas en las Capas Ocultas\n",
    "\n",
    " Intente cambiar el numero de neuronas del modelo acutual y observe cómo afecta el rendimiento del modelo.\n",
    "\n",
    "1. Cambie el número de neuronas a 256 en cada capa oculta:\n",
    " \n",
    "2. Cambie el número de neuronas a 1024 en cada capa oculta:\n",
    "\n",
    "**Pregunta:**\n",
    "- ¿Cómo cambia la precisión y la pérdida del modelo con diferentes números de neuronas en las capas ocultas?\n",
    "\n",
    "  Al cambiar el número de neuronas de 10 a 256 en la primera y segunda capa oculta, la precisión obtenida fue de un 80% y la pérdida fue de 39.35%, en\n",
    "  comparación con la anterior configuración en que la precisión y la pérdida fueron de 96.67% y 18.48% respectivamente. Por lo tanto el rendimiento del\n",
    "  modelo con 256 neuronas fue mucho menor que con 10.\n",
    "\n",
    "  El rendimiento obtenido con 1024 neuronas fue similar aunque un poco mejor al obtenido con 10, ya que la precisión del modelo fue de 96.67% y la\n",
    "  pérdida fue de 7.29%. Es decir el rendimiento con 1024 neuronas fue mejor que con 10 y 256.\n",
    "\n",
    "#### Desafío 3: Cambiar la Cantidad de Épocas de Entrenamiento\n",
    "\n",
    "El modelo actual se entrena durante 50 épocas. Intente cambiar el número de épocas de entrenamiento y observe cómo afecta el rendimiento del modelo.\n",
    "\n",
    "1. Cambie el número de épocas a 10:\n",
    "\n",
    "\n",
    "2. Cambie el número de épocas a 30:\n",
    " \n",
    "**Pregunta:**\n",
    "- ¿Cómo afecta el número de épocas a la precisión y la pérdida del modelo durante el entrenamiento y la validación? ¿Observa algún signo de sobreajuste o subajuste?\n",
    "\n",
    "  Al cambiar el número de épocas de 50 a 10 la diferencia obtenida en el rendimiento del modelo es significativa, la precisión y pérdida obtenida fue\n",
    "  de 70% y 63.67% respectivamente.\n",
    "\n",
    "  Al utilizar 30 épocas el ajuste y el rendimiento del modelo es mucho mejor en comparación al utilizar 10 épocas. La precisión y pérdida obtenida fue\n",
    "  96.67% 7 26.70%, por lo que el rendimiento es ligeramente menor que al utilizar 50 épocas.\n",
    "\n",
    "  Por lo tanto se podría decir que al utilizar mayor número de épocas al momento de entrenar el modelo, se puede obtener un mejor ajuste y por lo tanto\n",
    "  un mejor rendimiento del modelo al momento de utilizarlo y/o evaluarlo.\n",
    "\n",
    "#### Desafío 4: Modificar la Función de Activación en las Capas Ocultas\n",
    "\n",
    "El modelo actual utiliza la función de activación ReLU en las capas ocultas. Intente usar una función de activación diferente y observe cómo afecta el rendimiento del modelo.\n",
    "\n",
    "1. Cambie la función de activación a `sigmoid`:\n",
    "\n",
    "\n",
    "2. Cambie la función de activación a `tanh`:\n",
    "\n",
    "\n",
    "**Pregunta:**\n",
    "- ¿Cómo afectan las diferentes funciones de activación en las capas ocultas a la precisión y la pérdida del modelo durante el entrenamiento y la validación?\n",
    "\n",
    "  Al cambiar la función de activación a `sigmoid` en las capas ocultas, la precisión fue menor y la pérdida fue mayor que con la función de activación `ReLu`. La precisión obtenida fue 63.33% y la pérdida 53.35%.\n",
    "\n",
    "  Con la función de activación `tanh` la precisión fue mucho mayor y la pérdida menor sobretodo en comparación con `ReLu` que con `sigmoid`. La precisión y pérdida obtenida fueron 100% y 8.52% respectivamente.\n",
    "\n",
    "  Dicho esto, se pudo apreciar que el rendimiento obtenido por el modelo utilizando como función de activación la tangente hiperbólica `tanh` durante el entrenamiento y validación de los datos utilizados fue mucho mejor que las otras funciones de activación utilizadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fdb24c-3afa-4686-b92a-f06a4ea92f07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
